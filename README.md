
-----

# Projet NexSlice : Scheduler Kubernetes Intelligent (IA/Heuristique)

**Auteurs :** Ryan ZERHOUNI, Anas FERRAH, Sam BOUCHET, Othmane TAIRECH

**Contexte :** Projet 4 - Scheduler Intelligent avec IA pour R√©seau 5G Slicing

**Environnement utilis√© :** macOS (Apple Silicon M4 Pro) / OrbStack / K3d

-----

## 1\. Introduction et Objectifs

Dans un contexte de Network Slicing 5G, le placement des fonctions r√©seaux (UPF, SMF) ne peut pas √™tre al√©atoire. Le scheduler par d√©faut de Kubernetes (`kube-scheduler`) se base sur les ressources *demand√©es* (Requests) et non sur l'utilisation *r√©elle*. Cela peut mener √† des goulots d'√©tranglement sur des n≈ìuds surcharg√©s.

**Objectif du projet :** D√©velopper un **Custom Scheduler** capable de :

1.  Intercepter les pods critiques avant leur assignation.
2.  Analyser la consommation **r√©elle** (CPU/RAM en temps r√©el) des n≈ìuds via l'API Metrics.
3.  Placer intelligemment les pods sur le n≈ìud le moins charg√© (Load Balancing dynamique).

-----

## 2\. √âtat de l‚Äôart : scheduling 5G cloud-native et limites de Kubernetes

### 2.1 5G, network slicing et exigences de QoS

La 5G introduit le **network slicing** pour faire cohabiter sur la m√™me infrastructure des services aux besoins tr√®s diff√©rents (eMBB, URLLC, mMTC). Chaque *slice* correspond √† un r√©seau logique de bout en bout, avec ses propres fonctions r√©seau (RAN, c≈ìur 5G) et ses propres objectifs de performance (latence, d√©bit, isolation, fiabilit√©).

Les sp√©cifications 3GPP (TS 28.530, 28.531, 28.532, 28.533) d√©finissent :
- le mod√®le d‚Äôinformation des slices,
- les op√©rations de cycle de vie (cr√©ation / modification / suppression),
- et les KPIs / SLA √† respecter pour la QoS.

Cela impose :
- une **latence faible** (en particulier pour l‚ÄôURLLC),
- un **d√©bit garanti** (eMBB),
- une **isolation logique** des ressources (CPU, m√©moire, bande passante),
- une **√©lasticit√© dynamique** pour suivre la demande.

SchedulerTa3IA s‚Äôinscrit dans ce contexte : son objectif est d‚Äôam√©liorer le placement des fonctions r√©seau pour mieux respecter ces contraintes de QoS dans un environnement Kubernetes.

### 2.2 Cloud-native 5G et r√¥le de Kubernetes

Avec la 5G, les fonctions r√©seau migrent de VNFs monolithiques vers des **Cloud-Native Network Functions (CNFs)**, packag√©es en conteneurs et orchestr√©es par Kubernetes. Plusieurs c≈ìurs 5G open source (OpenAirInterface, Open5GS, etc.) adoptent cette approche.

Dans ce cadre :
- Kubernetes fournit le **plan de contr√¥le** pour cr√©er / supprimer / scaler les pods,
- assure le **service discovery** (Services, EndpointSlices),
- et s‚Äôappuie sur un composant cl√© : le **kube-scheduler**, responsable du placement des pods sur les n≈ìuds.

SchedulerTa3IA s‚Äôins√®re dans cette architecture cloud-native : il se connecte √† n‚Äôimporte quel cluster Kubernetes (y compris un d√©ploiement existant de type NexSlice) pour exp√©rimenter et appliquer des politiques de scheduling sp√©cifiques au slicing 5G, en venant **compl√©ter** le comportement du kube-scheduler par d√©faut gr√¢ce √† une couche d‚ÄôIA ‚Äî sans modifier ni forker Kubernetes.

### 2.3 kube-scheduler : fonctionnement et limites pour le slicing 5G

Le kube-scheduler effectue classiquement deux √©tapes :
1. **Filtrage** des n≈ìuds admissibles (ressources disponibles, taints/tolerations, affinit√©s, etc.).
2. **Scoring** pour choisir le ‚Äúmeilleur‚Äù n≈ìud via diff√©rents plugins.

M√™me si le *Scheduling Framework* permet d‚Äôajouter des plugins custom (Filter, Score, Bind, ‚Ä¶), le scheduler par d√©faut reste centr√© sur :
- les **requests/limits** CPU et m√©moire d√©clar√©es par les pods,
- et quelques contraintes de topologie (labels, zones).

En revanche, pour le slicing 5G, il ne prend pas nativement en compte :
- la **latence r√©seau** entre n≈ìuds,
- la **bande passante disponible**,
- le **type de fonction 5G** (UPF, SMF, AMF, CU/DU),
- ni les **objectifs SLA sp√©cifiques √† un slice** (latence cible, d√©bit, isolement).

Cons√©quence : le placement pod-par-pod peut aboutir √† :
- des slices **partiellement d√©ploy√©es**,
- un **gaspillage de ressources** (CPU/√©nergie),
- et un **non-respect** des contraintes de latence ou d‚Äôisolation.

SchedulerTa3IA r√©pond √† ce manque en introduisant un scheduler IA externe qui se base sur l‚Äô**utilisation r√©elle** CPU/RAM des n≈ìuds et des crit√®res m√©tier, ce que kube-scheduler ne fait pas par d√©faut.

### 2.4 Approches avanc√©es pour le scheduling 5G et microservices

La litt√©rature r√©cente explore plusieurs pistes pour am√©liorer le scheduling dans des sc√©narios 5G cloud-native :

#### a) Heuristiques et m√©taheuristiques

Des travaux mod√©lisent le placement des slices comme un probl√®me de **Virtual Network Embedding (VNE)**, et utilisent des heuristiques (dont des algorithmes g√©n√©tiques) pour :
- d√©cider si une slice enti√®re est admissible (*all-or-nothing*),
- optimiser le **taux d‚Äôacceptation** des slices,
- r√©duire la **consommation √©nerg√©tique** et le temps de d√©ploiement.

SchedulerTa3IA se place dans cette famille *heuristique/IA*, avec une approche volontairement simple et explicable : un **Score de Disponibilit√©** bas√© sur la charge CPU/RAM r√©elle pour chaque n≈ìud, combin√© √† une logique de d√©cision pilot√©e par l‚ÄôIA pour guider le placement.

#### b) Ordonnanceurs ‚Äúnetwork-aware‚Äù et co-scheduling

D‚Äôautres ordonnanceurs se focalisent sur la **latence r√©seau** et les **graphes de communication** entre pods :
- prise en compte d‚Äôune matrice latence/bande passante entre n≈ìuds,
- co-scheduling de groupes de pods (une application ou un slice complet) plut√¥t que pod par pod,
- co-localisation de fonctions fortement coupl√©es (par ex. UPF‚ÄìgNB/DU, UPF‚ÄìSMF/AMF).

Ces approches visent √† r√©duire la latence inter-pods et √† mieux exploiter la topologie r√©seau, ce qui est critique pour les services 5G sensibles √† la QoS.

#### c) Schedulers bas√©s sur le Machine Learning / Reinforcement Learning

Un troisi√®me axe consiste √† utiliser l‚Äô**apprentissage par renforcement (RL / DRL)** pour apprendre automatiquement une politique de placement sur Kubernetes. Les travaux existants montrent que le RL peut :
- observer l‚Äô√©tat du cluster (charge CPU/m√©moire, m√©triques applicatives),
- choisir dynamiquement le n≈ìud pour chaque pod,
- optimiser simultan√©ment **latence**, **taux de compl√©tion**, **√©quilibrage de charge** et **utilisation des ressources**.

Au-del√† de Kubernetes, le DRL est aussi appliqu√© au **network slicing** (c≈ìur + RAN), o√π l‚Äôallocation de ressources entre slices est vue comme un probl√®me de d√©cision s√©quentielle multi-objectif.

---

**Positionnement de SchedulerTa3IA :**  
SchedulerTa3IA ne cherche pas (encore) √† concurrencer toutes les approches avanc√©es de type RL ou m√©taheuristiques compl√®tes. Il se positionne comme un **scheduler IA l√©ger** qui **compl√®te** le kube-scheduler, facile √† d√©ployer et √† comprendre. Il ne repose pas sur NexSlice ni sur un d√©ploiement sp√©cifique : c‚Äôest un composant ind√©pendant que l‚Äôon peut brancher en surcouche sur diff√©rents environnements Kubernetes (dont NexSlice) pour en optimiser le comportement de scheduling.

Il montre concr√®tement :

- qu‚Äôun ordonnanceur sp√©cialis√© 5G peut am√©liorer l‚Äô**√©quilibrage de charge r√©el** par rapport au kube-scheduler par d√©faut,
- qu‚Äôexposer la **t√©l√©m√©trie r√©elle** (Metrics Server) et des r√®gles IA de d√©cision au scheduler est d√©j√† un levier puissant pour mieux respecter les contraintes du slicing 5G,
- et qu‚Äôil peut √™tre int√©gr√© √† des solutions existantes (par exemple un environnement NexSlice) pour en **optimiser** l‚Äôordonnancement sans en changer l‚Äôarchitecture.

-----

## 3\. M√©thodologie et Architecture

### 3.1 Choix Technologiques

  * **Langage : Python**. Choisi pour sa rapidit√© de prototypage et sa richesse en librairies pour l'interaction API (vs Go qui est plus complexe pour un POC).
  * **Infrastructure : K3d (via OrbStack)**. Permet de simuler un cluster multi-n≈ìuds (1 Master + 2 Agents) sur une architecture ARM64 locale.
  * **Donn√©es : Metrics Server**. Nous n'utilisons pas Prometheus (trop lourd pour ce prototype) mais l'API native `metrics.k8s.io` pour obtenir la t√©l√©m√©trie en temps r√©el.

### 3.2 Algorithme de D√©cision (L'IA Heuristique)

Contrairement au placement statique, notre algorithme calcule un **Score de Disponibilit√©** pour chaque n≈ìud en temps r√©el.

$$
\text{Score} =
\frac{
  (100 - \text{CPU}_{\text{utilis√©}})
  +
  (100 - \text{RAM}_{\text{utilis√©e}})
}{2}
$$

  * Plus le score est √©lev√©, plus le n≈ìud est vide.
  * Le scheduler s√©lectionne le n≈ìud avec le **Score Max**.

### 3.3 Architecture Technique

1.  **Filtrage :** Le script √©coute les pods ayant le statut `Pending` et le champ `schedulerName: nexslice-ai`.
2.  **Collecte :** Interrogation de l'API `/apis/metrics.k8s.io/v1beta1/nodes`.
3.  **Normalisation :** Conversion des unit√©s h√©t√©rog√®nes (millicores, nanocores, KiB, MiB) en pourcentages standardis√©s.
4.  **Binding :** Cr√©ation directe d'un objet `Binding` via l'API, court-circuitant le scheduler par d√©faut.

-----

## 4\. Impl√©mentation (Les Scripts)

### 4.1 Le Cerveau : `ai_scheduler.py`

Ce script est le c≈ìur du projet. Il tourne en continu pour surveiller et assigner les pods.

```python
import time
import json
import os
import subprocess
from kubernetes import client, config, watch

config.load_kube_config()
v1 = client.CoreV1Api()
cust = client.CustomObjectsApi()
scheduler_name = "nexslice-ai"

print(f"üìä Scheduler IA '{scheduler_name}' d√©marr√© (Mode: REAL METRICS & CLEAN UNITS)...")

def parse_cpu(quantity):
    """ Normalise tout en Millicores """
    s = str(quantity)
    if s.endswith('n'): return int(s[:-1]) / 1_000_000 
    if s.endswith('m'): return int(s[:-1])             
    if s.endswith('u'): return int(s[:-1]) / 1000      
    return float(s) * 1000                             

def parse_mem(quantity):
    """ Normalise tout en MiB """
    s = str(quantity)
    if s.endswith('Ki'): return int(s[:-2]) / 1024
    if s.endswith('Mi'): return int(s[:-2])
    if s.endswith('Gi'): return int(s[:-2]) * 1024
    return int(s) / (1024*1024) 

def get_real_node_metrics():
    node_stats = {}
    try:
        nodes = v1.list_node().items
        metrics = cust.list_cluster_custom_object("metrics.k8s.io", "v1beta1", "nodes")
    except:
        return {}

    capacities = {}
    for n in nodes:
        capacities[n.metadata.name] = {
            'cpu': parse_cpu(n.status.allocatable['cpu']),
            'mem': parse_mem(n.status.allocatable['memory'])
        }

    for item in metrics['items']:
        name = item['metadata']['name']
        if "server" in name: continue

        usage_cpu = parse_cpu(item['usage']['cpu'])
        usage_mem = parse_mem(item['usage']['memory'])
        
        cap_cpu = capacities[name]['cpu']
        cap_mem = capacities[name]['mem']

        pct_cpu = (usage_cpu / cap_cpu) * 100 if cap_cpu > 0 else 0
        pct_mem = (usage_mem / cap_mem) * 100 if cap_mem > 0 else 0

        node_stats[name] = {"cpu_pct": pct_cpu, "mem_pct": pct_mem}
        
    return node_stats

def score_node(pod, stats):
    free_cpu = 100 - stats['cpu_pct']
    free_ram = 100 - stats['mem_pct']
    score = (free_cpu + free_ram) / 2
    print(f"   [Mertics] CPU: {stats['cpu_pct']:.2f}% | RAM: {stats['mem_pct']:.2f}% -> Score: {score:.2f}")
    return score

def bind(pod, node):
    binding = {
        "apiVersion": "v1", "kind": "Binding",
        "metadata": {"name": pod.metadata.name, "namespace": pod.metadata.namespace},
        "target": {"apiVersion": "v1", "kind": "Node", "name": node}
    }
    filename = f"bind-{pod.metadata.name}.json"
    with open(filename, 'w') as f: json.dump(binding, f)
    
    try:
        subprocess.run(f"kubectl create -f {filename}", shell=True, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
        print(f"‚úÖ SUCC√àS : Pod assign√© √† {node}")
        os.remove(filename)
    except: pass

def main():
    w = watch.Watch()
    for event in w.stream(v1.list_pod_for_all_namespaces):
        pod = event['object']
        if pod.status.phase == "Pending" and pod.spec.scheduler_name == scheduler_name and pod.spec.node_name is None:
            print(f"\nüîé Pod d√©tect√© : {pod.metadata.name}")
            stats = get_real_node_metrics()
            best_node = None
            best_score = -9999
            
            for node, metrics in stats.items():
                print(f"   Node {node}:")
                final_score = score_node(pod, metrics)
                if final_score > best_score:
                    best_score = final_score
                    best_node = node
            
            if best_node: bind(pod, best_node)

if __name__ == '__main__':
    main()
```

### 4.2 Le Sc√©nario de Test Automatis√© : `demo_video.sh`

Ce script Bash orchestre la d√©monstration en g√©n√©rant de la charge CPU (Stress Test) pour forcer le scheduler √† r√©agir.

```bash
#!/bin/bash
# CONFIGURATION
NODE0="k3d-nexslice-cluster-agent-0"
NODE1="k3d-nexslice-cluster-agent-1"

# Fonction d'attente pour la synchro Metrics Server
wait_for_metrics() {
    echo -ne "Synchronization des m√©triques ($1s)... ["
    for ((i=1; i<=$1; i++)); do echo -ne "‚ñì"; sleep 1; done
    echo -e "] OK"
}

echo "=== NEXSLICE AI SCHEDULER - TEST DE VALIDATION END-TO-END ==="

# [PHASE 0] Initialisation
kubectl delete pods --all --grace-period=0 --force > /dev/null 2>&1
rm -f bind-*.json
echo -n "Nettoyage..."
while kubectl get pods 2>&1 | grep -q "Running\|Pending\|Terminating"; do echo -n "."; sleep 1; done
echo " DONE"

# [PHASE 1] STRESS TEST NODE 0
echo "Simulation de surcharge sur $NODE0..."
cat <<EOF | kubectl apply -f - > /dev/null
apiVersion: v1
kind: Pod
metadata: {name: overload-node-0}
spec:
  nodeName: $NODE0
  containers: [{name: stress, image: vish/stress, args: ["-cpus", "4"], resources: {requests: {cpu: "1000m"}}}]
EOF
wait_for_metrics 70

# [PHASE 2] D√âPLOIEMENT INTELLIGENT 1
echo "D√©ploiement Service Critique (Scenario: Evitement)..."
cat <<EOF | kubectl apply -f - > /dev/null
apiVersion: v1
kind: Pod
metadata: {name: webapp-1}
spec:
  schedulerName: nexslice-ai
  containers: [{name: nginx, image: nginx:alpine}]
EOF
sleep 5
ACTUAL_NODE=$(kubectl get pod webapp-1 -o jsonpath='{.spec.nodeName}')

if [ "$ACTUAL_NODE" == "$NODE1" ]; then
    echo "‚úÖ SUCC√àS : Le Pod a √©t√© plac√© sur $NODE1 (Le Node 0 √©tait satur√©)"
else
    echo "‚ùå √âCHEC : Le Pod est sur $ACTUAL_NODE"
fi

# [PHASE 3] BASCULEMENT DE CHARGE
echo "Inversion de la Topologie de Charge..."
kubectl delete pod overload-node-0 --grace-period=0 --force > /dev/null 2>&1
cat <<EOF | kubectl apply -f - > /dev/null
apiVersion: v1
kind: Pod
metadata: {name: overload-node-1}
spec:
  nodeName: $NODE1
  containers: [{name: stress, image: vish/stress, args: ["-cpus", "4"], resources: {requests: {cpu: "1000m"}}}]
EOF
wait_for_metrics 70

# [PHASE 4] D√âPLOIEMENT INTELLIGENT 2
echo "D√©ploiement Service Secondaire (Scenario: Retour)..."
cat <<EOF | kubectl apply -f - > /dev/null
apiVersion: v1
kind: Pod
metadata: {name: webapp-2}
spec:
  schedulerName: nexslice-ai
  containers: [{name: nginx, image: nginx:alpine}]
EOF
sleep 5
ACTUAL_NODE_2=$(kubectl get pod webapp-2 -o jsonpath='{.spec.nodeName}')

if [ "$ACTUAL_NODE_2" == "$NODE0" ]; then
    echo "‚úÖ SUCC√àS : Le Pod est revenu sur $NODE0"
else
    echo "‚ùå √âCHEC : Le Pod est sur $ACTUAL_NODE_2"
fi
```

-----

## 5\. R√©sultats et Validation

Les tests ont √©t√© effectu√©s en provoquant une saturation artificielle (Stress Test CPU \> 90%) s√©quentiellement sur chaque n≈ìud. Notre saturation n'a pu amener le CPU qu'a 14% mais ceci est suffisant puisque, √©tant donn√©e qu'on repartait d'un cluster kubernetes vierge, l'autre node √©tait a 0% d'utilisation de CPU.

### Sc√©nario A : Surcharge du N≈ìud Core (Agent-0)

  * **Condition :** Agent-0 CPU \> 10%. Agent-1 CPU \< 5%.
  * **D√©cision IA :** Le scheduler a d√©tect√© la charge et a assign√© le pod `webapp-1` sur l'**Agent-1**.
  * **Preuve :**

![Preuve succ√®s sc√©nario 1](Images/surcharge.png)
> *Capture d'√©cran 1 : D√©tection de surcharge et √©vitement.*

### Sc√©nario B : Basculement de charge (Failover)

  * **Condition :** La charge se d√©place sur l'Agent-1. L'Agent-0 redevient disponible.
  * **D√©cision IA :** Le scheduler a redirig√© le nouveau flux `webapp-2` vers l'**Agent-0**.
  * **Preuve :**

![Preuve succ√®s sc√©nario 1](Images/r√©√©quilibrage.png)
> *Capture d'√©cran 2 : Retour √† la normale et r√©√©quilibrage.*

-----

## 6\. Guide de Reproduction

Pour reproduire ces r√©sultats sur un environnement neuf :

1.  **Pr√©parer le Cluster :**

    ```bash
    k3d cluster create nexslice-cluster --agents 2
    ```

2.  **Installer le Metrics Server (Indispensable) :**

    ```bash
    git clone -b k3s https://github.com/AIDY-F2N/NexSlice.git
    cd NexSlice/    
    sudo kubectl apply -f metricserver.yaml
    ```

3.  **Lancer le Scheduler :**

    ```bash
    pip install kubernetes
    python3 ai_scheduler.py
    ```

4.  **Lancer le Sc√©nario de Test :**

    ```bash
    chmod +x demo_video.sh
    ./demo_video.sh
    ```

-----

## 7. Validation Finale : Benchmark R√©el (Default vs NexSlice)

Afin de valider scientifiquement notre approche, nous avons d√©velopp√© un script de benchmark avanc√© (`benchmark_ai.py`) qui compare, sur le m√™me cluster et avec la m√™me charge, les d√©cisions du **Scheduler Kubernetes par d√©faut** face √† **NexSlice AI**. Pour reproduire ce test il faut executer `ai_scheduler.py` puis ensuite lancer `benchmark_ai.py`. Ce dernier va a la fin du test g√©n√©rer un graphique sous format png.

`benchmark_ai.py` :

```bash
import time
import subprocess
import matplotlib.pyplot as plt
import numpy as np
import os

# CONFIGURATION
NODE0 = "k3d-nexslice-cluster-agent-0"
NODE1 = "k3d-nexslice-cluster-agent-1"

print("üöÄ D√âMARRAGE DU BENCHMARK ULTIME (Safe File Mode)...")

# --- FONCTIONS UTILITAIRES ---
def clean_cluster():
    print("üßπ Nettoyage complet du cluster...")
    subprocess.run("kubectl delete pods --all --grace-period=0 --force", shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
    if os.path.exists("bind-*.json"): subprocess.run("rm bind-*.json", shell=True)
    if os.path.exists("temp_bench.yaml"): subprocess.run("rm temp_bench.yaml", shell=True)
    time.sleep(5)

def apply_yaml_safely(yaml_content):
    """ √âcrit le YAML dans un fichier avant de l'appliquer (√âvite les erreurs de syntaxe Bash) """
    with open("temp_bench.yaml", "w") as f:
        f.write(yaml_content)
    try:
        subprocess.run("kubectl apply -f temp_bench.yaml", shell=True, check=True, stdout=subprocess.DEVNULL)
    except subprocess.CalledProcessError:
        print("‚ùå Erreur lors de l'application du YAML.")

def get_node_cpu_percent():
    try:
        output = subprocess.check_output("kubectl top nodes --no-headers", shell=True).decode()
        stats = {}
        for line in output.splitlines():
            parts = line.split()
            if "unknown" in parts[2]: return 0
            stats[parts[0]] = int(parts[2].replace('%', ''))
        return stats
    except: return None

def measure_load_for(seconds, label):
    print(f"   ‚è± Mesure de la charge ({seconds}s)...")
    max_n0 = 0
    max_n1 = 0
    for i in range(seconds):
        stats = get_node_cpu_percent()
        if stats:
            c0 = stats.get(NODE0, 0)
            c1 = stats.get(NODE1, 0)
            if c0 > max_n0: max_n0 = c0
            if c1 > max_n1: max_n1 = c1
            if i % 5 == 0: print(f"      T+{i}s | Node 0: {c0}% | Node 1: {c1}%")
        time.sleep(1)
    print(f"   üìä R√âSULTAT {label} -> Node 0 Max: {max_n0}% | Node 1 Max: {max_n1}%")
    return max_n0, max_n1

# ==========================================
# PHASE 1 : REAL DEFAULT SCHEDULER
# ==========================================
clean_cluster()
print("\nüî• [PHASE 1/2] TEST DU 'DEFAULT SCHEDULER'...")

# 1. Charge de base
yaml_base = f"""
apiVersion: v1
kind: Pod
metadata:
  name: stress-base
spec:
  nodeName: {NODE0}
  containers:
  - name: s
    image: vish/stress
    args: ["-cpus", "3"]
    resources:
      requests:
        cpu: "1000m"
"""
apply_yaml_safely(yaml_base)

# 2. Client Standard (Default Scheduler)
yaml_client_default = """
apiVersion: v1
kind: Pod
metadata:
  name: client-default
spec:
  containers:
  - name: c
    image: vish/stress
    args: ["-cpus", "3"]
    resources:
      requests:
        cpu: "100m"
"""
apply_yaml_safely(yaml_client_default)

# 3. Mesure
print("   -> Attente stabilisation...")
time.sleep(10)
default_n0, default_n1 = measure_load_for(20, "DEFAULT SCHEDULER")


# ==========================================
# PHASE 2 : REAL NEXSLICE AI SCHEDULER
# ==========================================
clean_cluster()
print("\nü§ñ [PHASE 2/2] TEST DU 'NEXSLICE AI SCHEDULER'...")

# 1. Charge de base
apply_yaml_safely(yaml_base)
print("   -> Charge de base lanc√©e. Attente stabilisation (10s)...")
time.sleep(10)

# 2. Client Intelligent
yaml_client_ai = """
apiVersion: v1
kind: Pod
metadata:
  name: client-ai
spec:
  schedulerName: nexslice-ai
  containers:
  - name: c
    image: vish/stress
    args: ["-cpus", "3"]
    resources:
      requests:
        cpu: "100m"
"""
apply_yaml_safely(yaml_client_ai)
print("   -> Client IA demand√©.")

# 3. Mesure
print("   -> Mesure de l'√©quilibrage...")
time.sleep(5)
ai_n0, ai_n1 = measure_load_for(20, "AVEC IA")

# ==========================================
# G√âN√âRATION GRAPHIQUE
# ==========================================
print("\nüìà G√âN√âRATION DU RAPPORT DE PERFORMANCE...")
if not os.path.exists('images'): os.makedirs('images')

labels = ['Default Scheduler', 'NexSlice AI']

# Donn√©es Node 0 (Core)
data_n0 = [default_n0, ai_n0]
# Donn√©es Node 1 (Edge)
data_n1 = [default_n1, ai_n1]

fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))

# Graphique 1 : Charge Max sur Node 0
# Le default devrait √™tre plus haut ou √©gal. Si le default a bien √©quilibr√©, ils seront √©gaux.
# Si le default a mal jou√©, la barre rouge sera plus haute.
ax1.bar(labels, data_n0, width=0.5, color=['#e74c3c', '#2ecc71'])
ax1.set_title('Impact sur le N≈ìud C≈ìur (Surcharge)')
ax1.set_ylabel('Charge CPU R√©elle (%)')
ax1.bar_label(ax1.containers[0], fmt='%d%%', padding=3)
ax1.legend(['Charge CPU'])

# Graphique 2 : Activation du Node 1
ax2.bar(labels, data_n1, width=0.5, color=['gray', '#3498db'])
ax2.set_title('Utilisation du N≈ìud Edge (D√©lestage)')
ax2.set_ylabel('Ressources Utilis√©es (%)')
ax2.bar_label(ax2.containers[0], fmt='%d%%', padding=3)

filename = "images/ultimate_benchmark.png"
plt.savefig(filename)
print(f"‚úÖ SUCC√àS : Graphique g√©n√©r√© -> {filename}")

```

### 7.1 Protocole Scientifique
Le test se d√©roule en deux phases strictement identiques :
1.  **Phase A (Default Scheduler) :** Nous saturons le N≈ìud 0 (C≈ìur), puis nous lan√ßons un client lourd sans instruction de placement. Kubernetes d√©cide seul.
2.  **Phase B (NexSlice AI) :** Nous nettoyons le cluster, saturons de nouveau le N≈ìud 0, puis laissons notre IA placer le client lourd.

**M√©trique choisie : Le PIC de Charge (Peak Load)**
Nous avons choisi de mesurer la charge CPU **maximale atteinte** (et non la moyenne). Dans un r√©seau 5G (Slicing), ce sont les pics de charge qui cr√©ent la gigue (jitter) et violent les SLA de latence. Le but est d'√©cr√™ter ces pics.

### 7.2 R√©sultats Obtenus

![R√©sultats Benchmark Ultime](ai_scheduler/images/ultimate_benchmark.png)

### 7.3 Analyse des Donn√©es
Les r√©sultats sur notre environnement de test (Apple Silicon M4 Pro)  montrent deux tendances claires :

1.  **Protection du N≈ìud C≈ìur (Gauche) :**
    * **Default Scheduler (Rouge) :** Le n≈ìud critique atteint un pic de **21%**. Le scheduler par d√©faut a ajout√© de la charge sur un n≈ìud d√©j√† sollicit√©.
    * **NexSlice AI (Vert) :** Le n≈ìud critique est maintenu √† **17%**. L'IA a d√©tect√© la saturation et a totalement d√©vi√© la nouvelle charge.
    * *Gain :* Une r√©duction de la pression sur le n≈ìud critique, garantissant une meilleure stabilit√© pour les processus existants.

2.  **Activation du N≈ìud Edge (Droite) :**
    * Bien que le scheduler par d√©faut ait fini par utiliser le N≈ìud Edge (probablement par comportement Round-Robin), notre IA a r√©alis√© ce d√©lestage de mani√®re **d√©terministe** et plus efficace (consommation globale plus stable).

**Note technique :** Les pourcentages absolus peuvent sembler bas (20%) car les conteneurs de stress sont tr√®s l√©gers pour la puissance de calcul de la machine h√¥te (M4 Pro). Cependant, le **diff√©rentiel** valide l'algorithme : NexSlice AI lisse la charge mieux que le standard Kubernetes.

## 8\. Conclusion

Ce projet d√©montre la faisabilit√© d'un **scheduler intelligent externe** pour Kubernetes. En moins de 150 lignes de code Python, nous avons impl√©ment√© un syst√®me de **Load Balancing r√©actif** bas√© sur la t√©l√©m√©trie r√©elle.

Contrairement au scheduler par d√©faut, cette solution est adapt√©e aux contraintes du **Network Slicing 5G** o√π la performance r√©elle prime sur la r√©servation th√©orique des ressources. L'int√©gration a √©t√© valid√©e par des tests de stress dynamiques montrant une redirection du trafic en moins de 60 secondes.